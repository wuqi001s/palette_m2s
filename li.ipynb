{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Download model and save the model to git_root/model/celebahq/200_Network.pth\n",
    "2. Modify inpainting_celebahq.json\n",
    "    [\"path\"][\"resume_state\"]: \"model/celebahq/200\"\n",
    "    [\"datasets\"][\"test\"][\"args\"][\"data_root\"]: \"<Folder Constains Inference Images>\"\n",
    "\n",
    "    (optinally) change [\"model\"][\"which_networks\"][\"args\"][\"beta_schedule\"][\"test\"][\"n_timestep\"] value to reduce # steps inference should take\n",
    "                more steps yields better results\n",
    "3. Modify in your particular case in this code:\n",
    "    model_pth = \"<PATH-TO-MODEL>/200_Network.pth\"\n",
    "    input_image_pth = \"<PATH-TO-DATASET_PARENT_DIT>/02323.jpg\"\n",
    "5. Run inpainting code (assume save this code to git_root/inference/inpainting.py)\n",
    "    cd inference\n",
    "    python inpainting.py -c ../config/inpainting_celebahq.json -p test\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "import core.praser as Praser\n",
    "import torch\n",
    "from core.util import set_device, tensor2img\n",
    "from data.util.mask import get_irregular_mask\n",
    "from models.network import Network\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "model_pth = \"/home/y/project/dm/Palette-Image-to-Image-Diffusion-Models/save_models/49_Network.pth\"\n",
    "input_image_pth = \"/home/y/project/dm/Palette-Image-to-Image-Diffusion-Models/s_image/Out_682_34.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CONFIG] [-p {train,test}] [-b BATCH]\n",
      "                             [-gpu GPU_IDS] [-d] [-P PORT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/y/.local/share/jupyter/runtime/kernel-v3f5f9f70bbaf08c041b21c700b0f8fde477a6f97e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-c', '--config', type=str,\n",
    "                        default='/home/y/project/dm/Palette-Image-to-Image-Diffusion-Models/config/inpainting_places2.json', help='JSON file for configuration')\n",
    "    parser.add_argument('-p', '--phase', type=str,\n",
    "                        choices=['train', 'test'], help='Run train or test', default='test')\n",
    "    parser.add_argument('-b', '--batch', type=int,\n",
    "                        default=16, help='Batch size in every gpu')\n",
    "    parser.add_argument('-gpu', '--gpu_ids', type=str, default=None)\n",
    "    parser.add_argument('-d', '--debug', action='store_true')\n",
    "    parser.add_argument('-P', '--port', default='21012', type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    opt = Praser.parse(args)\n",
    "    return opt\n",
    "\n",
    "\n",
    "# config arg\n",
    "opt = parse_config()\n",
    "model_args = opt[\"model\"][\"which_networks\"][0][\"args\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initializa model\n",
    "model = Network(**model_args)\n",
    "state_dict = torch.load(model_pth)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "model.set_new_noise_schedule(phase='test')\n",
    "model.eval()\n",
    "\n",
    "tfs = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# read input and create random mask\n",
    "img_pillow = Image.open(input_image_pth).convert('RGB')\n",
    "img = tfs(img_pillow)\n",
    "mask = get_irregular_mask([256, 256])\n",
    "mask = torch.from_numpy(mask).permute(2, 0, 1)\n",
    "cond_image = img*(1. - mask) + mask*torch.randn_like(img)\n",
    "mask_img = img*(1. - mask) + mask\n",
    "\n",
    "# save conditional image used a inference input\n",
    "cond_image_np = tensor2img(cond_image)\n",
    "Image.fromarray(cond_image_np).save(\"./result/cond_image.jpg\")\n",
    "\n",
    "# set device\n",
    "cond_image = set_device(cond_image)\n",
    "gt_image = set_device(img)\n",
    "mask = set_device(mask)\n",
    "\n",
    "# unsqueeze\n",
    "cond_image = cond_image.unsqueeze(0).to(device)\n",
    "gt_image = gt_image.unsqueeze(0).to(device)\n",
    "mask = mask.unsqueeze(0).to(device)\n",
    "\n",
    "# inference\n",
    "with torch.no_grad():\n",
    "    output, visuals = model.restoration(cond_image, y_t=cond_image,\n",
    "                                        y_0=gt_image, mask=mask, sample_num=8)\n",
    "\n",
    "# save intermediate processes\n",
    "output_img = output.detach().float().cpu()\n",
    "for i in range(visuals.shape[0]):\n",
    "    img = tensor2img(visuals[i].detach().float().cpu())\n",
    "    Image.fromarray(img).save(f\"./result/process_{i}.jpg\")\n",
    "\n",
    "# save output (output should be the same as last process_{i}.jpg)\n",
    "img = tensor2img(output_img)\n",
    "Image.fromarray(img).save(\"./result/output.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 5 required positional arguments: 'networks', 'losses', 'sample_num', 'task', and 'optimizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 实例化模型\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPalette\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 根据你的代码调整参数，例如 in_channels, out_channels 等\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 5 required positional arguments: 'networks', 'losses', 'sample_num', 'task', and 'optimizers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# 假设你的 Palette 模型定义在 model.py 中\n",
    "from models.model import Palette\n",
    "from models.guided_diffusion_modules.unet import UNet\n",
    "# 设置设备\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 实例化模型\n",
    "# 根据你的代码调整参数，例如 networks, losses, sample_num, task, optimizers\n",
    "networks = UNet()  # 假设 UNet 是你的网络定义\n",
    "losses = None  # 替换为实际的损失函数\n",
    "sample_num = 10  # 替换为实际的样本数量\n",
    "task = \"image-to-image\"  # 替换为实际任务\n",
    "optimizers = None  # 替换为实际的优化器\n",
    "\n",
    "model = Palette(networks=networks, losses=losses, sample_num=sample_num, task=task, optimizers=optimizers)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 文件路径\n",
    "ema_path = \"/home/y/project/dm/Palette-Image-to-Image-Diffusion-Models/save_models/49_Network_ema.pth\"\n",
    "network_path = \"/home/y/project/dm/Palette-Image-to-Image-Diffusion-Models/save_models/49_Network.pth\"\n",
    "state_path = \"/home/y/project/dm/Palette-Image-to-Image-Diffusion-Models/save_models/49.state\"\n",
    "\n",
    "\n",
    "# 加载权重函数\n",
    "def load_palette_model(model, ema_path=None, network_path=None, state_path=None):\n",
    "    if os.path.exists(ema_path):\n",
    "        state_dict = torch.load(ema_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded EMA weights from {ema_path}\")\n",
    "    elif os.path.exists(network_path):\n",
    "        state_dict = torch.load(network_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded network weights from {network_path}\")\n",
    "    elif os.path.exists(state_path):\n",
    "        checkpoint = torch.load(state_path, map_location=device)\n",
    "        if \"model_state_dict\" in checkpoint:\n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            print(f\"Loaded model state from {state_path}\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)  # 如果 .state 直接是 state_dict\n",
    "            print(f\"Loaded checkpoint from {state_path}\")\n",
    "    \n",
    "    model.eval()  # 设置为推理模式\n",
    "    return model\n",
    "\n",
    "# 加载模型\n",
    "model = load_palette_model(model, ema_path, network_path, state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
